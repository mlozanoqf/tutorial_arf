---
title: ''
#output: bookdown::gitbook:
  html_document:
    df_print: paged
---

```{r load libraries Merton.}
library(knitr)
library(plotly)
library(Sim.DiffProc)
library(scatterplot3d)
library(vembedr)
```

```{r echo=FALSE}
# This removes all items in environment. 
# It is a good practice to start your code this way.
rm(list=ls())
```

# The Merton model.

The Merton model is useful when we are interested in evaluating the credit risk of public firms. In short, it evaluates how likely it is that the value of the future firm's assets fall below a certain threshold represented by the firm's debt. By doing that, the model is able to estimate a probability of default among other results. The model can be used as a tool to propose changes (for example) in the balance sheet to reduce the credit risk exposure of a firm.

The philosophy of these models goes back to @black1973pricing, @merton1973theory and @merton1974pricing, they consider corporate liabilities as contingent claims on the assets of the firm.

## Minimize a function in R.

The estimation of the credit risk Merton's model requires a minimization of a function. In this section, we show a simple minimization example. Here are some useful online resources for further references.

* [FRM: How d2 in Black-Scholes becomes PD in Merton model.](https://youtu.be/lV0ytJYbVzc)
* [Normal Probability Distribution Graph. Interactive.](https://www.intmath.com/counting-probability/normal-distribution-graph-interactive.php)
* [How to use optim in R.](https://www.r-bloggers.com/how-to-use-optim-in-r/)

The objective function to be minimized is $f(a,b)=\sum(a + bx_i-y_i)^2$. We have six values for $x$ and $y$, and we are expected to minimize the function $f$ by finding the parameter values $a$ and $b$. The $x_i$ and $y_i$ data looks like this:

```{r}
# Data.
dat <- data.frame(x = c(1, 2, 3, 4, 5, 6), y = c(1, 3, 5, 6, 8, 12))
kable(dat, caption = "Observations.", row.names = TRUE) # The table.
```

Graphically:

```{r fig.cap="Original data."}
# A scatter plot.
plot(y ~ x, data = dat, pch = 19, cex = 2)
```

Let's implement the $f(a,b)=\sum(a + bx_i-y_i)^2$ minimization.

```{r}
# Function that calculates the residual sum of squares.
min.RSS <- function(data, par) {
  with(data, sum((par[1] + par[2] * x - y)^2)) }
# Function minimization.
result <- optim(par = c(0, 1), min.RSS, data = dat)
a <- result$par[1]
b <- result$par[2]
f <- sum((a + b * dat$x - dat$y)^2)
# Minimization output.
ans <- data.frame(a, b, f)
kable(ans, caption = "Minimization results f(a,b).")
```

The minimization result is represented by a line, and the line is characterized by an intercept equal to $-1.266846$ and a slope equal to $2.02862$. 

We can plot it and verify that this is indeed the right answer.

```{r fig.cap="Line that minimize the residual sum of squares."}
# View the results.
plot(y ~ x, data = dat, pch = 19, ylim = c(-2, 12), xlim = c(0, 6), cex = 2)
abline(a, b, col = "red", lwd = 3)
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
```

The function that we minimize here is basically the OLS criterion. This is why the regression model leads to the same results.

```{r}
# The previous example is equivalent as a linear regression model.
reg <- lm(y ~ x, data = dat)
# See the results.
summary(reg)
```

The function that we minimize in the estimation of the credit risk Merton model is more elaborated, but we follow the same principle as above.

## The estimation.

For an introductory reference to understand the basics of credit see @brealey2020principles. 

Let's follow the example 24.3 in [@Hull]. We have five parameters: $E_0=3$, $\sigma_E=0.8$, $rf=0.05$, $T=1$, $D=10$ that lead to an estimate of the value of the assets today $V_0$ and the volatility of the assets $\sigma_V$. With these seven parameters we can estimate the probability of default $pd$ among other interesting results.

These are the known parameters.

```{r}
# List of known parameters.
E0 <- 3 # Value of the equity as today, this is market capitalization.
se <- 0.8 # Stock return volatility.
rf <- 0.05 # Risk-free rate.
TT <- 1 # Maturity.
D <- 10 # Value of the debt. The Bloomberg function DDIS is useful.
```
We need equations 24.3 and 24.4 to estimate $V_0$ and $\sigma_V$.

```{r}
eq24.3 <- function(V0, sv) { 
  ((V0 * pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) -
  D * exp(-rf * TT) * pnorm(((log(V0 / D) +
  (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) - sv * sqrt(TT)) - E0)) }
eq24.4 <- function(V0, sv) { 
  ((pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) *
      sv * V0 - se * E0)) }
# Footnote 10 indicates that we should minimize F(x,y)^2+G(x,y)^2
min.footnote10 <- function(x) 
  (eq24.3(x[1], x[2]))^2 + (eq24.4(x[1], x[2]))^2
# The minimization leads to the values of V0 and sv.
V0_sv <- optim(c(1, 1), min.footnote10)
# Define the values as parameters.
V0 <- V0_sv$par[1]
sv <- V0_sv$par[2]
kable(data.frame("Market value" = V0, 
                 "Volatility" = sv), 
      caption = "Assets.")
```

Calculate the probability of default $N(-d_2)$ as a function of $V_0$ and $\sigma_V$.

```{r}
PD <- function(V0, sv) { 
  pnorm(-(((log(V0 / D) + (rf + sv^2 / 2) * TT) / 
             (sv * sqrt(TT))) - sv * sqrt(TT))) }
# Calculate the probability of default given the previous parameters.
pd <- PD(V0, sv)
pd
```
The probability of default is 12.69396%.

Let's analyze the role of the values of $d_1$, $d_2$, $N(d_1)$ and $N(d_2)$. First, we isolate these values.

```{r}
# Inspect the role of d and N(d).
d1 <- (log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))
d2 <- d1 - sv * sqrt(TT)
Nd1 <- pnorm(d1)
Nd2 <- pnorm(d2)
ans <- data.frame(d1, Nd1, d2, Nd2)
ans
```


Now, let's illustrate how $N(-d_2)$ lead to the probability of default given the properties of a standard normal distribution.


```{r fig.cap="The red area represents the probability of default."}
xseq <- seq(-4, 4, 0.01) 
densities <- dnorm(xseq, 0, 1) # Standard normal distribution.
# Graphical evaluation of N(-d_2).
plot(xseq, densities, xlab = "d values (-d_2 is the dotted line)", 
     ylab = "Density", type = "l", lwd = 2, cex = 2)
abline(h = 0)
polygon(c(xseq[xseq >= -d2], -d2), c(densities[xseq >= -d2], 0), col = "green")
polygon(c(xseq[xseq < -d2], -d2), c(densities[xseq < -d2], 0), col = "red")
legend("topleft", legend = c("N(d_2)=0.8730604 
in green and
N(-d_2)=0.1269396 in red.

N(d_2)+N(-d_2)=1."),
bg = "white", bty = "n", cex = 0.9)
abline(v = -d2, lty = 2, lwd = 3)
```

Now, let's analyze the minimization that leads to $V_0$ and $\sigma_V$. We do not have an analytic math expressions (closed form) to calculate $V_0$ and $\sigma_V$, instead we have approximate values or estimates given the minimization of equations 24.3 and 24.4 in [@Hull]. In order to see how good this approximation is, we can retrieve the value of $[F(x,y)]^2+[G(x,y)]^2$ evaluated at $x=V_0$ and $y=\sigma_v$. This value is supposed to be positive as both $F(x,y)$ and $G(x,y)$ functions are squared, so we expect a positive number close to zero when evaluated at $x=V_0$ and $y=\sigma_v$.

```{r}
# Evaluate how good is the minimization.
min.footnote10(x = c(V0, sv))
round(min.footnote10(x = c(V0, sv)), 6)
```

The minimization conducted in the function <tt>`min.footnote10()`</tt> above worked fairly well as the value is zero in practical terms.

There is another way to approach how the minimization work. We can propose a graphical analysis. In particular, we can verify whether $V_0=12.39578$ and $\sigma_V=0.2123041$ minimizes the objective function. To illustrate this in two axis, we need to fix either $V_0$ or $\sigma_V$, and evaluate $[F(x,y)]^2+[G(x,y)]^2$ with different values of $V_0$ or $\sigma_V$. Let's do that.

```{r}
# Fix sv and evaluate different values of V0.
V0.seq <- seq(from = 4, to = 20, length.out = 100)
sv.rep <- rep(sv, 100)
# Function to be evaluated.
FG <- function(V0, sv) { (eq24.3(V0, sv))^2 + (eq24.4(V0, sv))^2 }
# Apply the function with fixed sv and different V0 values.
FG.V0 <- mapply(FG, V0.seq, sv.rep)
```

We are ready to plot.

```{r fig.cap="Here we fix the volatility of the assets and change the value of the assets at time zero. The minimization looks fine."}
# Plot the results.
plot(V0.seq, FG.V0, type = "l", xlab = expression(paste(V[0])),
     ylab = expression(paste(F(x,y)^2+G(x,y)^2)), cex.lab = 0.8, lwd = 3)
abline(v = V0, lty = 2)
abline(h = FG(V0, sv), lty = 2)
points(V0, FG(V0, sv), pch = 1, cex = 3, col = "red", lwd = 2)
```

Clearly, the minimization worked well here. For the sake of completeness, now we fix the $V_0$ value and evaluate the function again.

```{r fig.cap="Here we fix the value of the assets at time zero and change the volatility of the assets. The minimization looks fine."}
# Now fix V0, and evaluate different sv values.
sv.seq <- seq(0, 0.6, length.out = 100)
V0.rep <- rep(V0, 100)
# Evaluate the function with these parameters.
FG.sv <- mapply(FG, V0.rep, sv.seq)
# Plot the results.
plot(sv.seq, FG.sv, type = "l", xlab = expression(paste(sigma[V])), 
     ylab = expression(paste(F(x, y)^2 + G(x, y)^2)), 
     cex.lab = 0.8, lwd = 3)
abline(v = sv, lty = 2)
abline(h = FG(V0, sv), lty = 2)
points(sv, FG(V0, sv), pch = 1, cex = 3, col = "red", lwd = 2)
```

We can show the same as before but in a 3D plot.

```{r fig.cap="Minimization of the function."}
# outer evaluates the function for each combination of the vectors.
z <- outer(V0.seq, sv.seq, FG) # z is now 100x100 matrix.
persp(V0.seq, sv.seq, z, col = "springgreen", shade = 0, xlab = "V0",
      ylab = "sv", zlab = "Objective function.")
```
Contour plots or level plots are a way to show a three-dimensional surface on a two-dimensional plane.

```{r fig.cap="Minimization of the function: a contour view."}
# The nlevels is high to emphasize the minimum value in blue.
contour(V0.seq, sv.seq, z, xlab = expression(paste(V[0])), 
        ylab = expression(paste(sigma[V])), 
        lwd = 2, nlevels = 300)
points(V0, sv, pch = 19, col = "blue", cex = 2)
```

The following plot cannot be seen in a PDF output, but it can be seen in a browser as an interactive plot. This green plot is nice but it is not interactive. We could plot interactive three-dimension plots with other R packages like <tt>`plotly`</tt> and show them in a html context or java environment. 


```{r fig.cap="Minimization of the function: an interactive view."}
plot_ly(type = "surface" , x = sv.seq, y = V0.seq , z = z ) %>%
layout(#title = "Minimization of f at V0=12.395 an sv=0.212",
       scene = list(xaxis = list(title = "Assets volatility"), 
                    yaxis = list(title = "Assets", 
                    zaxis = list(title = "f=F^2+G^2"))))  %>%
hide_colorbar()
#add_markers(y = 12.3957765, x = 0.2123041, z = 0, inherit = TRUE)
```

The Merton model allows us to calculate more values in this credit risk assessment. 

```{r}
# Other results in the Merton's model.
market_value_debt <- V0 - E0
pv_promised_payment_debt <- D * exp(-rf * TT)
Expected_Loss <- (pv_promised_payment_debt - market_value_debt) /
  pv_promised_payment_debt
recovery_rate <- 1 - (Expected_Loss / pd)
ans <- data.frame(market_value_debt, pv_promised_payment_debt, 
                  Expected_Loss, recovery_rate, pd)
kable(t(ans), caption = "Other results in the Merton's model.")
```

Could we figure out the implied bond yield spread? It would be similar to the fair interest rate that this firm has to pay given its probability of default and recovery rate. Take Hull's equation 24.2 as a reference: $\lambda(T)=S(T)/(1-R)$ and solve for $S(T)$: $S(T)=\lambda(T)\times(1-R)$, so $S(T)=(0.12693963)\times(1-0.90350393)$. This is 122.4918 basis points more than the risk-free rate. Then, with five parameters we can calculate (among other things) the firm's probability of default and the correspondent yield spread of this firm's bond. It would be interesting to compare this value with the market yield spread and evaluate whether the market yield is over or underestimated according to our theoretical value. 

This is the spread function.

```{r}
spread <- function(E0, se, rf, TT, D) { 
  eq24.3 <- function(V0, sv) { 
  ((V0 * pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) - 
      D * exp(-rf * TT) * pnorm(((log(V0 / D) +
  (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) - sv * sqrt(TT)) - E0)) }
eq24.4 <- function(V0, sv) { 
  ((pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) *
      sv * V0 - se * E0)) }
  min.footnote10 <- function(x) 
  (eq24.3(x[1], x[2]))^2 + (eq24.4(x[1], x[2]))^2
V0_sv <- optim(c(1, 1), min.footnote10)
V0 <- V0_sv$par[1]
sv <- V0_sv$par[2]
pd <- pnorm(-(((log(V0 / D) + (rf + sv^2 / 2) * TT) /
          (sv * sqrt(TT))) - sv * sqrt(TT)))

market_value_debt <- V0 - E0
pv_promised_payment_debt <- D * exp(-rf * TT)
Expected_Loss <- (pv_promised_payment_debt - market_value_debt) /
  pv_promised_payment_debt
recovery_rate <- 1 - (Expected_Loss / pd)
spread <- pd * (1-recovery_rate)
spread
}
```

Let's evaluate the spread function.

```{r}
spread(E0 = 3, se = 0.8, rf = 0.05, TT = 1, D = 10)
```


```{r eval=FALSE, include=FALSE}
x.T <- seq(0.5, 10, 0.5)
spread.T <- mapply(spread, E0 = 3, se = 0.8, rf = 0.05, x.T, D = 10)
```


```{r eval=FALSE, include=FALSE}
data.frame(x.T, spread.T)
```

## Inside view of the Merton's model.

The model assumes that the assets follow a geometric Brownian motion stochastic process. A regular Wiener stochastic process looks like this.


```{r}
embed_url("https://youtu.be/X-VRWeqG_I8")
```

Let's go back to our main example and assume the daily evolution of the market value of the firm assets over a year. Here are 10 simulated paths of $V_t$ from $t=0,...,T$. The reference of this section is [@Hull] Chapter 14 and 15.

```{r fig.cap="Simulation of 10 paths of the assets."}
# Merton assumes V follows a geometric Brownian motion process.
V0.sim <- function(i) {  # the argument i is not used here.
  GBM(N = 365, T = 1, t0 = 0, x0 = V0, theta = 0.05, sigma = sv) }
set.seed(3) # Reproducibility  
paths <- sapply(1:10, V0.sim) # Create 10 paths for V.
# Plot results.
matplot(paths, type = "l", col = "black", lwd = 1, lty = 1,
        ylab = expression(paste(V[t])), 
        xlab = "Time in days (from 0 to T)")
abline(h = D, col = "red", lwd = 2)
points(1, V0, pch = 19, cex = 1.5, col = "blue")
points(rep(366, 8), paths[366, paths[366, ] > 10], 
       pch = 1, cex = 1.5, col = "green")
points(rep(366, 2), paths[366, paths[366, ] < 10], 
       pch = 1, cex = 1.5, col = "red")
```

These simulations can be interpreted as the evolution of the value of the firm's assets in 10 parallel universes. In the past, some students have called this figure *la grÃ¡fica de los pelitos*, this is OK as long as you understand the figure implications. The right name is 10 simulated geometric Brownian motion processes. Let's count the cases in which $V_t<D$ note that here I use $t$ and not $T$, so we are counting the cases in which at least at some time $t$ the value of the assets were lower than 10. 

```{r}
# Which path went lower than D?
which(colSums(paths < 10) > 0)
```
The value of the assets was lower than $10 at some time in the second, fourth and ninth alternate universes. Let's plot these cases.

```{r fig.cap="Note that the blue path finally did not default. Recovery is possible as in the real life."}
# There might be an easier way to select these cases.
matplot(paths[,which(colSums(paths < 10) > 0)], type = "l", 
        col = c("green", "blue", "red"), lwd = 2, lty = 1,
        ylab = expression(paste(V[t])), 
        xlab = "Time in days (from 0 to T)")
abline(h = D, col = "red", lwd = 2)
points(1, V0, pch = 19, cex = 1.5, col = "blue")
```

The blue path was lower than 10 at some time, but at $t=T$ it is clearly higher than 10. For this reason, the blue path does not represent a firm's default. See how the assets are not high enough to pay the debt at maturity only in two cases: green and red. Thus, according to this simulation the probability of default is 20%. Here is how we can calculate the cases in which $V_T<D$.

```{r}
sum(paths[366,] < 10) / 10
```

The probability of default of 20% can be disappointing because it is significantly higher than 12.693963%. This is because the number of simulations is small. The following examples show how these values tend to converge as we increase the number of simulations from 10 to 100 and to 100,000.

Here are 100 simulated paths of $V_0$ to $V_T$.

```{r fig.cap="Simulation of 100 paths of the assets."}
set.seed(3) # Reproducibility  
paths <- sapply(1:100, V0.sim) # Create 100 paths.
# Plot results.
matplot(paths, type = "l", col = "black", lwd = 1, lty = 1,
        ylab = expression(paste(V[t])), 
        xlab = "Time in days (from 0 to T)")
abline(h = D, col = "red", lwd = 2)
points(1, V0, pch = 19, cex = 1.5, col = "blue")
```

Given the simulation above, the probability of default is 17%. This is closer to 12.693963%.

```{r}
sum(paths[366,] < 10) / 100
```

Let's see all the 17 cases that end in default.

```{r fig.cap="Default cases."}
# These are the 17 default cases.
matplot(paths[,which(paths[366,] < 10)], type = "l", col = "black", 
        lwd = 1, lty = 1, ylab = expression(paste(V[t])), 
        xlab = "Time in days (from 0 to T)")
abline(h = D, col = "red", lwd = 2)
points(1, V0, pch = 19, cex = 1.5, col = "blue")
```

Now, let's see the 11 cases in which $V_t$ eventually went lower than $10 but at the end did not default. 

```{r fig.cap="All these paths went lower than 10 at some point, but at the end the value of the assets are higher than 10. These are paralell universes in which the firm finally survived after some drama."}
# V_t < 10
almost_default <- which(colSums(paths < 10) > 0)
# V_T < 10
default <- which((paths[366,] < 10))
# There should be an easier way to do this:
matplot(paths[,almost_default[which(almost_default %in% 
                                      default == FALSE)]], 
        type = "l", col = c(1:11), lwd = 1, lty = 1, 
        ylab = expression(paste(V[t])), 
        xlab = "Time in days (from 0 to T)")
abline(h = D, col = "red", lwd = 2)
points(1, V0, pch = 19, cex = 1.5, col = "blue")
```

Here are 100,000 simulated $V_T$ showed in a histogram. The reference for this section is 15.1 ([@Hull]). Note that instead of drawing the complete paths, we can directly get the distribution of $V_T$. The resulting distribution is log-normal.

```{r fig.cap="Histogram of 100,000 values of the assets at maturity."}
set.seed(13)
# 100,000 values of VT at once.
VT <- exp(rnorm(100000, log(V0) + (rf - (sv^2) / 2)*TT, sv*sqrt(TT)))
# Plot results.
h <- hist(VT, 100, plot = FALSE)
ccat <- cut(h$breaks, c(-Inf, D, Inf))
# You may also need to change the xlim if a big red square appears as changes in maturity may imply larger values of VT. I recommend trying without xlim and see.
plot(h, main = NULL, col = c("red", "blue")[ccat], 
     xlab = "Value of the assets at maturity", xlim = c(4, 30))
legend("topright", 
legend = c("The red area is 12.657%, and represents
the simulated probability of default.
The probability of default of the model
following the textbook example is 
N(-d_2)=12.69396%. As we can see,
both are very close."),
col = c("red", "blue"), pch = c(19), bg = "white", bty = "n", cex = 0.8)
```

The probability of default can be calculated as:

```{r}
sum(VT < 10) / 100000
```

Note that 0.12657 is now much closer than 0.12693963. Convergence achieved.

This firm can be represented as an European call option payoff. The payoff of a typical stock option is $c=max(S_T-K, 0)$ or equivalently in terms of Merton's model: $E_T=max(V_T-D, 0)$.

```{r fig.cap="A view of the firm's balance sheet in the future. Looks like a typical European call option payoff."}
ET <- pmax(VT - D, 0) # payoff function of a typical call option.
plot(sort(VT), sort(ET), type = "l", lwd = 4, xlim = c(5, 20), 
     ylim = c(0, 10), xlab = "Simulated assets at maturity (V_T)",
     ylab = "Simulated equity at maturity (E_T)")
abline(v = 10, lty = 2)
legend("left", legend = c("According to the model,
E_T=0 happens 
in 12.657% of the 
100,000 cases."),
bg = "white", bty = "n", cex = 0.9)
```

This diagram show the firm's market values in the future at maturity. This is because the $E_T$ is a function of $V_T$ and $D$. As long as $V_T<D$, then the value of $E_T=0$. Otherwise, the value of $E_T= V_T-D$, just as the accounting equation suggest but in future terms. Note that the Merton's model says nothing about the estimated value of $E_T$, instead we have an estimate about how likely is that $V_T<D$, or in other words how likely is that $E_T<0$.

Then, we know that $E_T= max(V_T-D, 0)$. The Black-Scholes-Merton formula can also estimate the theoretical value of $E_0$. This is, if the observable market value given by the market capitalization available in any financial site is $E_0=3$, we can retrieve the theoretical value of $E_0$ so we can compare whether the firm observable market value is over or undervalued. In other words, the Black-Scholes-Merton model can give us an estimate of the firm value. In particular, the model gives the value of the equity today as:

$E_0=V_0N(d_1)-De^{-rT}N(d_2)$

This is equation 24.3 in [@Hull]. To estimate $E_0$, we need $V_0$ and $\sigma_V$ and these two values were already estimated before with the implementation of the min.footnote10 function above. It is true that this minimization requires $E_0$, the point here is to use the observable market capitalization $E_0=3$ to find out the unobservable $V_0$ and $\sigma_V$ and then estimate the theoretical value of $E_0$.

The code is:

```{r}
# Black-Scholes call.
E0.theo <- function(V0, D, rf, TT, sv) {
  d1 <- (log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))
  d2 <- d1 - sv * sqrt(TT)
  c <- V0 * pnorm(d1) - D * exp(-rf * TT) * pnorm(d2)
}
V0 <- 12.39578 # Assets.
D <- 10 # Debt.
rf <- 0.05 # Risk-free rate.
TT <- 1 # Maturity.
sv <- 0.2123041 # Volatility of assets.
(E0.theo(V0, D, rf, TT, sv))
```
Then, we can argue that the market value of the firm is slightly undervalued since the theoretical value of the firm is 3.000357 compared with 3. This approach opens the possibility to value firms. It also opens the possibility to compare the book value in the Balance sheet of the total assets versus the estimate $V_0$. This will allow us to understand the difference between book value and market value of the assets, not only of the equity. We can even implement a similar analysis about the market value of the debt just as we did before. 

## The probability of default as a function of some parameters.

We can expand our analysis by evaluating how changes in parameters change the probability of default in the context of the Merton model. This is interesting because we can move from estimating a probability of default to propose changes in the firm's parameters like the capital structure to reduce a firm's probability of default. First, we need the probability of default as a function.

```{r}
pd <- function(E0, se, rf, TT, D) { 
  eq24.3 <- function(V0, sv) { 
  ((V0 * pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) -
  D * exp(-rf * TT) * pnorm(((log(V0 / D) +
  (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) - sv * sqrt(TT)) - E0)) }
eq24.4 <- function(V0, sv) { 
  ((pnorm((log(V0 / D) + (rf + sv^2 / 2) * TT) / (sv * sqrt(TT))) *
      sv * V0 - se * E0)) }
  min.footnote10 <- function(x) 
  (eq24.3(x[1], x[2]))^2 + (eq24.4(x[1], x[2]))^2
V0_sv <- optim(c(1, 1), min.footnote10)
V0 <- V0_sv$par[1]
sv <- V0_sv$par[2]
pd <- pnorm(-(((log(V0 / D) + (rf + sv^2 / 2) * TT) /
          (sv * sqrt(TT))) - sv * sqrt(TT)))
pd }
```

Now we have a convenient function: $pd = f(E_0, \sigma_E, rf, T, D)$. Remember these five parameters are required to estimate $V_0$ and $\sigma_V$ before calculating $pd$.

```{r}
# Evaluate the case of the textbook example.
pd1 <- pd(3, 0.8, 0.05, 1, 10)
pd1
```

Now, we create vectors of parameters and evaluate the <tt>`pd`</tt> function.

```{r}
l = 50 # Vectors of length 50.
# Create vectors of the parameters.
x.E <- seq(from = 1, to = 20, length.out = l)
x.rf <- seq(0, 4, length.out = l)
x.D <- seq(1, 20, length.out = l)
x.T <- seq(0.5, 20, length.out = l)
x.se <- seq(0, 3, length.out = l)
# Evaluate the pd at different values.
pd.E <- mapply(pd, x.E, se, rf, TT, D)
pd.rf <- mapply(pd, E0, se, x.rf, TT, D)
pd.D <- mapply(pd, E0, se, rf, TT, x.D)
pd.T <- mapply(pd, E0, se, rf, x.T, D)
pd.se <- mapply(pd, E0, x.se, rf, TT, D)
```


Let's plot the probability of default as a function of equity. What we are doing here is to evaluate the probability of default function 50 times, as the $E_0$ has 50 values from 1 to 20. By doing this, we end up with 50 values of the probability of default. 

```{r fig.cap="The probability of default as a function of the equity at time zero."}
plot(x.E, pd.E, type = "l", ylab = "Probability of default", 
     xlab = "Equity at time zero", lwd = 3, ylim = c(0, 0.15))
lines(x.E, pd.E)
abline(v = E0, lty = 2)
abline(h = pd1, lty = 2)
points(E0, pd1, pch = 1, cex = 3, col = "red", lwd = 2)
```

These relationships between the parameters and the probability of default are all non-linear. This is interesting because according to the model, the current levels of the parameters are important when deciding which parameter might lead to a high or low impact over the probability of default.

```{r fig.cap="The probability of default as a function of the risk-free rate."}
plot(x.rf, pd.rf, type = "l", ylab = "Probability of default", 
     xlab = "Risk-free rate", lwd = 3)
abline(h = 0, lty = 2)
abline(v = rf, lty = 2)
abline(h = pd1, lty = 2)
points(rf, pd1, pch = 1, cex = 3, col = "red", lwd = 2)
```

Probability of default as a function of debt. Note that adding 1 or subtracting 1 unit of debt has different impact over the probability of default.

```{r fig.cap="The probability of default as a function of the debt."}
plot(x.D, pd.D, type = "l", ylab = "Probability of default", 
     xlab = "Debt", lwd = 3, ylim = c(0, 0.15))
abline(h = 0, lty = 2)
abline(v = D, lty = 2)
abline(h = pd1, lty = 2)
points(D, pd1, pch = 1, cex = 3, col = "red", lwd = 2)
```

Probability of default as a function of maturity. Note that asking for a higher debt maturity (as in a negotiation), do not lead to a lower probability of default if we keep the rest of the parameters unchanged in our firm. Imagine we arrange a meeting with the bank manager and we ask for more time to pay our debt. The bank manager should not (in principle) extend the debt maturity as long as we commit to do some changes in the firm. For example, we can negotiate a longer maturity and promise to increase the firm's equity.

```{r fig.cap="The probability of default as a function of the debt's maturity."}
plot(x.T, pd.T, type = "l", ylab = "Probability of default", 
     xlab = "Maturity", lwd = 3)
abline(h = 0, lty = 2)
abline(v = TT, lty = 2)
abline(h = pd1, lty = 2)
points(TT, pd1, pch = 1, cex = 3, col = "red", lwd = 2)
```

Probability of default as a function of the volatility of the equity $\sigma_E$.

```{r fig.cap="The probability of default as a function of the volatility of the equity."}
plot(x.se, pd.se, type = "l", ylab = "Probability of default",
     xlab = "Standard deviation of equity", lwd = 3)
abline(h = 0, lty = 2)
abline(v = se, lty = 2)
abline(h = pd1, lty = 2)
points(se, pd1, pch = 1, cex = 3, col = "red", lwd = 2)
```


In the previous plots we evaluate the probability of default function by changing one of the following parameters: $E_0$, $\sigma_E$, $rf$, $T$ or $D$. We were able to do that because we constructed a vector of 50 different values for these five parameters. Note that $V_0$ and $\sigma_V$ do not remain fixed because they are at the same time a function of $E_0$, $\sigma_E$, $rf$, $T$ and $D$. Now, let's start by plotting the probability of default as a function of $E_0$ and $\sigma_E$.

One alternative is to evaluate the probability of default function 50 times by taking the 50 pairs of values of $E_0$ and $\sigma_E$. By doing that, we will end with three vectors of size 50 that we can plot as a three dimension scatter plot.

```{r fig.cap="The probability of default as a function of the equity at time zero and the volatility of equity."}
ED <- mapply(pd, x.E, x.se, rf, TT, D)
p.ED <- scatterplot3d(x.E, x.se, ED, pch = 16, type = "h", color = 1:50, 
                      angle = 100, xlab = "Equity at time zero", 
                      ylab = "Volatility of equity", 
                      zlab = "Probability of default")
p.ED$points3d(E0, se, pd1, type = "h", col = "red", pch = 20, cex = 3)  
```

The red point represent the case of the original textbook example in which $pd = f(E_0=3, \sigma_E=0.8,rf=0.05,T=1,D=10)=0.1269396$. Note that the red point is not part of the 50 plotted observations simply because there is no case in which the probability of default function is evaluated in $E_0=3, \sigma_E=0.8$. Although the plot above is not incorrect, it might be incomplete as we are not showing all possible values of the probability of default. One alternative to show a more complete plot is to evaluate all possible combinations of $E_0$ and $\sigma_E$ to evaluate the probability of default function. If we do that, we will have 50 values for $E_0$ and $\sigma_E$ that represent the $x$ and $y$ axis, and a $50 \times 50$ matrix containing the probability of default. This allows us to plot a surface plot and a contour plot.

```{r}
# Create the empty matrix.
p_E_se <- matrix(0, nrow = l, ncol = l)
# Fill the empty matrix with probability of default values.
for(i in 1 : l){ # Is there an easier way to do this?
  for(j in 1 : l){
    p_E_se[i,j] <- mapply(pd, x.E[i], x.se[j], rf, TT, D) } }
```

Let's plot the results.

```{r fig.cap="The probability of default as a function of the equity at time zero and the volatility of equity: A plane or surface view."}
# Plot results.
p.ED1 <- persp(x.E, x.se, p_E_se, zlab = "pd", 
               xlab = "Equity at time zero", 
               ylab = "Volatility of equity", theta = 60, phi = 10, 
               expand =  0.5, col = "orange", shade = 0.2, 
               ticktype = "detailed") 
# Add the original pd value as in the textbook example.
points(trans3d(E0, se, pd1, p.ED1), cex = 2, pch = 19, col = "blue")
```

Now the plot becomes a plane. A contour plot simplify the reading of a three dimension plot by reducing it into two dimensions: $x$ and $y$ coordinates. The value of the probability of default is represented by the contour lines. 

```{r fig.cap="The probability of default as a function of the equity at time zero and the volatility of equity: A contour view."}
contour(x.E, x.se, p_E_se, xlab = "Equity at time zero", 
        ylab = "Volatility of equity", lwd = 2)
points(E0, se, pch = 19, col = "blue", cex = 2)
```      

The blue point is the original case. Note that the value is slightly higher than 0.1, which is consistent with the $pd=0.1269396$.

```{r}
l = 40 # Vectors of length 50.
# Create vectors of the parameters.
x.E <- seq(from = 2, to = 4, length.out = l)
x.se <- seq(0.2, 1.5, length.out = l)
# Create the empty matrix.
p_E_se <- matrix(0, nrow = l, ncol = l)
# Fill the empty matrix with probability of default values.
for(i in 1 : l){ # Is there an easier way to do this?
  for(j in 1 : l){
    p_E_se[i,j] <- mapply(pd, x.E[i], x.se[j], rf, TT, D) } }
```

```{r fig.cap="The probability of default as a function of the equity at time zero and the volatility of equity: An interactive view."}
plot_ly(type = "surface" , x = x.se, y = x.E , z = p_E_se ) %>%
layout(#title = "Minimization of f at V0=12.395 an sv=0.212",
       scene = list(xaxis = list(title = "Volatility of equity"), 
                    yaxis = list(title = "Market value of equity"), 
                    zaxis = list(title = "Probability of default")))  %>%
  hide_colorbar()
#add_markers(y = 3, x = 0.8, z = 0.1269396, inherit = TRUE)
```

## GoT: capital structure.

The problem. Daenerys Targaryen owns a big manufacturing firm that produces fire extinguishers. Surprisingly, the firm data corresponds exactly as the data in the example 24.3 ([@Hull]). She is planning to ask the Iron Bank of Braavos for a loan using the peaceful civilized way (without dragons). However, she would like to reduce the probability of default of the firm first, in that way she might negotiate better credit conditions. Daenerys has some understanding about very basic finance because she knows that she could either reduce the debt, or increase the capital in order to reduce the probability of default. Doing both alternatives at the same time is clearly more expensive so she is not very keen about it. 

What is the best strategy to reduce the probability of default? Reduce the debt by 2 or increase the capital by 2?

```{r}
D.seq <- seq(from = 0, to = 13, by = 0.1)
# Evaluate pd function: E0 changes from 1 to 5; debt goes from 0 to 13.
E1 <- mapply(pd, 1, se, rf, TT, D.seq)
E2 <- mapply(pd, 2, se, rf, TT, D.seq)
E3 <- mapply(pd, 3, se, rf, TT, D.seq)
E4 <- mapply(pd, 4, se, rf, TT, D.seq)
E5 <- mapply(pd, 5, se, rf, TT, D.seq)
```

Plot the results.

```{r fig.cap="GoT problem. Probability of default and capital structure."}
# We use these vectors for colors and legends in the following plots.
colors <- c("green", "purple", "black", "blue", "red")
leg <- c("E0=1", "E0=2", "E0=3 (initial value)", "E0=4", "E0=5")
# Plot.
plot(D.seq, E1, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=10",
     ylab = "Probability of default. Initially PD=12.69%")
lines(D.seq, E2, col = "purple", lwd = 3)
lines(D.seq, E3, col = "black", lwd = 3)
lines(D.seq, E4, col = "blue", lwd = 3)
lines(D.seq, E5, col = "red", lwd = 3)
abline(v = D, lty = 2)
abline(h = pd1, lty = 2)
legend("bottomright", legend = leg, lwd = rep(3, 5), col = colors, 
       bg = "white")
points(D, pd1, pch = 19, cex = 2)
```

Let's illustrate the alternatives as clear as possible.

```{r fig.cap="GoT solution. Probability of default and capital structure."}
plot(D.seq, E1, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=10",
     ylab = "Probability of default. Initially PD=12.69%")
lines(D.seq, E2, col = "purple", lwd = 3)
lines(D.seq, E3, col = "black", lwd = 3)
lines(D.seq, E4, col = "blue", lwd = 3)
lines(D.seq, E5, col = "red", lwd = 3)
abline(v = D, lty = 2)
abline(v = 8, lty = 2)
abline(h = pd1, lty = 2)
abline(h = pd(E0, se, rf, TT, 8), lty = 2)
abline(h = pd(5, se, rf, TT, D), lty = 2)
legend("bottomright", legend = leg, lwd = rep(3, 5), col = colors, 
       bg = "white")
points(D, pd1, pch = 19, cex = 2)
points(D, pd(5, se, rf, TT, D), pch = 19, cex = 2, col = "red")
points(8, pd(3, se, rf, TT, 8), pch = 19, cex = 2, col = "yellow")
```

Consider a different initial situation. Now, $E_0=2$ and $D=2$ and the rest remains the same. In this case, the probability of default is now 7.13%. What is the best strategy to reduce the probability of default? Reduce the debt by 1 or increase the capital by 1?

```{r fig.cap="GoT problem 2. Probability of default and capital structure."}
leg2 <- c("E0=1", "E0=2 (initial value)", "E0=3", "E0=4", "E0=5")

plot(D.seq, E1, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=2",
     ylab = "Probability of default. Initially PD=7.13%", 
     xlim = c(0, 2.5), ylim = c(0, 0.08))
lines(D.seq, E2, col = "purple", lwd = 3)
lines(D.seq, E3, col = "black", lwd = 3)
lines(D.seq, E4, col = "blue", lwd = 3)
lines(D.seq, E5, col = "red", lwd = 3)
abline(v = 2, lty = 2)
abline(h = pd(2, se, rf, TT, 2), lty = 2)
legend("bottomright", legend = leg2, lwd = rep(3, 5), col = colors, 
       bg = "white", cex = 0.6)
points(2, pd(2, se, rf, TT, 2), pch = 19, cex = 2, col = "purple")
```

The solution can be illustrated as follows:

```{r fig.cap="GoT solution 2. Probability of default and capital structure."}
plot(D.seq, E1, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=2",
     ylab = "Probability of default. Initially PD=7.13%", 
     xlim = c(0, 2.5), ylim = c(0, 0.08))
lines(D.seq, E2, col = "purple", lwd = 3)
lines(D.seq, E3, col = "black", lwd = 3)
lines(D.seq, E4, col = "blue", lwd = 3)
lines(D.seq, E5, col = "red", lwd = 3)
abline(v = 2, lty = 2)
abline(v = 1, lty = 2)
abline(h = pd(2, se, rf, TT, 2), lty = 2)
abline(h = pd(2, se, rf, TT, 1), lty = 2)
abline(h = pd(E0, se, rf, TT, 2), lty = 2)
legend("bottomright", legend = leg2, lwd = rep(3, 5), col = colors, 
       bg = "white", cex = 0.6)
points(2, pd(2, se, rf, TT, 2), pch = 19, cex = 2, col = "purple")
points(1, pd(2, se, rf, TT, 1), pch = 19, cex = 2, col = "yellow")
points(2, pd(E0, se, rf, TT, 2), pch = 19, cex = 2)
```

Interesting.

Consider a third problem. In a parallel universe, Daenerys Targaryen's firm has some liquidity short-term troubles. She needs either more cash now or some more time to pay her current debt. She would like to know which alternative leads to the lowest increase of the probability of default. Add $2 more to her current debt, or ask for a half year more time to pay her current debt? 

```{r}
T1 <- mapply(pd, E0, se, rf, 0.5, D.seq)
T2 <- mapply(pd, E0, se, rf, 1, D.seq)
T3 <- mapply(pd, E0, se, rf, 1.5, D.seq)
T4 <- mapply(pd, E0, se, rf, 2, D.seq)
T5 <- mapply(pd, E0, se, rf, 2.5, D.seq)
```

```{r fig.cap="GoT problem 3. More debt or longer maturity?"}
leg3 <- c("T=2.5", "T=2", "T=1.5", "T=1", "T=0.5")

plot(D.seq, T5, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=6",
     ylab = "Probability of default. Initially PD=20.33%")
lines(D.seq, T4, col = "purple", lwd = 3)
lines(D.seq, T3, col = "black", lwd = 3)
lines(D.seq, T2, col = "blue", lwd = 3)
lines(D.seq, T1, col = "red", lwd = 3)
abline(v = 6, lty = 2)
abline(h = pd(E0, se, rf, 1.5, 6), lty = 2)
legend("bottomright", legend = leg3, lwd = rep(3, 5), col = colors, 
       bg = "white")
points(6, pd(E0, se, rf, 1.5, 6), pch = 19, cex = 2)
```

Let's visualize the result.

```{r fig.cap="GoT answer 3. More debt or longer maturity?"}
plot(D.seq, T5, type = "l", col = "green", lwd = 3,
     xlab = "Debt value. Initially, D=6",
     ylab = "Probability of default. Initially PD=20.33%")
lines(D.seq, T4, col = "purple", lwd = 3)
lines(D.seq, T3, col = "black", lwd = 3)
lines(D.seq, T2, col = "blue", lwd = 3)
lines(D.seq, T1, col = "red", lwd = 3)
abline(v = 6, lty = 2)
abline(v = 8, lty = 2)
abline(h = pd(E0, se, rf, 1.5, 6), lty = 2)
abline(h = pd(E0, se, rf, 2, 6), lty = 2)
abline(h = pd(E0, se, rf, 1.5, 6), lty = 2)
abline(h = pd(E0, se, rf, 1.5, 8), lty = 2)
legend("bottomright", legend = leg3, lwd = rep(3, 5), col = colors, 
       bg = "white")
points(6, pd(E0, se, rf, 1.5, 6), pch = 19, cex = 2)
points(8, pd(E0, se, rf, 1.5, 8), pch = 19, cex = 2, col = "yellow")
points(6, pd(E0, se, rf, 2, 6), pch = 19, cex = 2, col = "purple")
```

Nice.
